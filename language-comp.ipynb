{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMS W1002 Computing in Context: Computing in the Humanities  \n",
    "## Created by Dennis Tenen\n",
    "## Counting words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem 1:__ Convert 5-10 papers you have written into plain text. Write a function in Python that counts the frequencey (number of times it appears) of a specified word appearing in your text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns an int, the number of times the given word is found in the given file\n",
    "def how_often(file_name, key_word):\n",
    "    \n",
    "    from string import punctuation\n",
    "    from collections import Counter\n",
    "    \n",
    "    # open the file, get all the lines\n",
    "    with open(file_name, 'r', encoding = 'utf8')as f:\n",
    "        lines = f.read().splitlines()\n",
    "    \n",
    "    # all of the words in the text\n",
    "    keys = []\n",
    "    \n",
    "    # isolate all of the words in the text and add them to keys\n",
    "    for line in lines:\n",
    "        for word in line.split():\n",
    "            word = word.strip(punctuation).lower()\n",
    "            keys.append(word)\n",
    "            \n",
    "    # counts how often every word appears        \n",
    "    num_keys = Counter(keys)\n",
    "    print(num_keys)\n",
    "    \n",
    "    # find the given word and it's value in keys, return the value\n",
    "    for key in num_keys:\n",
    "        if key_word == key:\n",
    "            return num_keys[key]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_often('essay1.txt', 'goods')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem 2:__ Write a function in Python that returns a list of the `n` most frequently appearing words of length at least `l` in a text file. Your function should have 3 parameters, `n`, `l`, and `file_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of the n most frequent words of length l in a single text file\n",
    "def most_frequent(n, l, file_name):\n",
    "    \n",
    "    from string import punctuation\n",
    "    from collections import Counter\n",
    "    \n",
    "    # get all the lines in the file\n",
    "    with open(file_name, 'r', encoding = 'utf8') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        \n",
    "    # a list of all qualifying words\n",
    "    keys = []\n",
    "    \n",
    "    # if a word in the text is over length l, add it to the keys\n",
    "    for line in lines:\n",
    "        for word in line.split():\n",
    "            word = word.strip(punctuation).lower()\n",
    "            # check length of word before adding it\n",
    "            if len(word) >= l:\n",
    "                keys.append(word)\n",
    "                \n",
    "    # count how often every word appears            \n",
    "    num_keys = Counter(keys)\n",
    "    \n",
    "    # get the n most common words\n",
    "    common = num_keys.most_common(n)\n",
    "    print(common)\n",
    "    common_words = []\n",
    "    \n",
    "    # just the words, not their values\n",
    "    for element in common:\n",
    "        common_words.append(element[0])\n",
    "        \n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent(10, 4, 'essay1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem 3:__ Modify your function above so that the last parameter is variable length so that you may give it file names for as many files as you like and it will return the `n` most popular words of at least length `l` in the entire corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a list of the n most frequent words of length l in all of the files given\n",
    "def most_frequent2(n, l, *files):\n",
    "    \n",
    "    from string import punctuation\n",
    "    from collections import Counter\n",
    "    \n",
    "    # if no file names are given, don't do anything\n",
    "    if files == []:\n",
    "        return None\n",
    "    \n",
    "    # add all the text into one big string to analyze, then split by lines\n",
    "    text = ''\n",
    "    for file_name in files:\n",
    "        with open(file_name, 'r', encoding = 'utf8')as f:\n",
    "            text += f.read()    \n",
    "    lines = text.splitlines()\n",
    "    \n",
    "    # a list of all the qualifying words\n",
    "    keys = []\n",
    "    \n",
    "    # if a word in the text is over length l, add it to keys\n",
    "    for line in lines:\n",
    "        for word in line.split():\n",
    "            word = word.strip(punctuation).lower()\n",
    "            # check length\n",
    "            if len(word) >= l:\n",
    "                keys.append(word)\n",
    "                \n",
    "    # count how often every word appears         \n",
    "    num_keys = Counter(keys)\n",
    "    \n",
    "    # get n most common words across all texts\n",
    "    common = num_keys.most_common(n)\n",
    "    common_words = []\n",
    "    \n",
    "    # isolate the words from their frequencies\n",
    "    for element in common:\n",
    "        common_words.append(element[0])\n",
    "        \n",
    "    return common_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Problem 4:__ Use the functions you just wrote to analyze your own papers both individually and as a corpus. What are the 20 most popular words over length 5? Do they vary much from paper to paper? Why do you think this is? Write about what you discover.\n",
    "\n",
    "### Answer ###\n",
    "The 20 most popular words over length 5 in all of my papers were, *'which', 'because', 'would', 'erica', 'aasmi', 'their', 'looked', 'through', 'happiness', 'never', 'aristotle', 'there', 'goods', 'really', 'about', 'wealth', 'thought', 'people', 'every',* and *'little'*.  \n",
    "These results, when I compare them to the results of each individual paper, seem to be influenced by the two longest papers, __essay1__ and __essay6__. *'erica'* and *'aasmi'* are two main characters in the creative writing paper I used as __essay6__. *'aristotle'* was the main author I analyzed in my CC paper which served as __essay1__, where I talked a lot about *'goods'*, *'wealth'*, and *'happiness'*.  \n",
    "The list of every paper was different from the rest, probably because each paper was taken from an entirely different context. Included in my papers are two creative writing assignments, one CC essay, one ArtHum analysis, and one LitHum essay. Therefore, each list sort of revolves around the topic that I chose for the paper, with the most popular words being related to the topic I covered, as seen with the examples in the first paragraph. However, there were some words which remained consistently popular throughout most of my papers. These were, *'which', 'because', 'really'*, and *'would'*. I can then conclude that these words were the ones which I used most often in my papers, regardless of context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(most_frequent2(20, 5, 'essay1.txt', 'essay2.txt', 'essay3.txt', 'essay4.txt', 'essay5.txt', 'essay6.txt'),'\\n')\n",
    "print(most_frequent(20,5,'essay1.txt'),'\\n')\n",
    "print(most_frequent(20,5,'essay2.txt'),'\\n')\n",
    "print(most_frequent(20,5,'essay3.txt'),'\\n')\n",
    "print(most_frequent(20,5,'essay4.txt'),'\\n')\n",
    "print(most_frequent(20,5,'essay5.txt'),'\\n')\n",
    "print(most_frequent(20,5,'essay6.txt'),'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
